{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing models\n",
    "\n",
    "In this notebook i'm going to show how to compare scores of different models. Different models can perform better or worse on various problems as they more or less suited to certain types of prolems. So i often run code similar to below to see what kind of model works best - which direction to continue in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X,y = datasets.load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've loaded the dataset above. Now i'm going to define several models that seem suitable and see how they compare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "lr = LinearRegression()\n",
    "lasso = Lasso(alpha=0.01)\n",
    "rf = RandomForestRegressor(min_samples_leaf=5, min_samples_split=10)\n",
    "gbm  = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also interested in performance of a stacked model, so a model that uses predictions from several base models and feeds them to a second level model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "stacked = StackingCVRegressor(\n",
    "    regressors=(lr, lasso, rf, gbm),\n",
    "    meta_regressor=Lasso(alpha=15),\n",
    "    cv=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now the comparing. We define a list of models that we're interested in and output scores for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Lasso                      Score: 0.73 (+/- 0.07)\n",
      "Model LinearRegression           Score: 0.72 (+/- 0.03)\n",
      "Model RandomForestRegressor      Score: 0.85 (+/- 0.03)\n",
      "Model GradientBoostingRegressor  Score: 0.85 (+/- 0.05)\n",
      "Model Stacked                    Score: 0.86 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "\n",
    "models = [\n",
    "    ('Lasso', lasso),\n",
    "    ('LinearRegression', lr),\n",
    "    ('RandomForestRegressor', rf),\n",
    "    ('GradientBoostingRegressor', gbm),\n",
    "    ('Stacked', stacked),\n",
    "]\n",
    "\n",
    "for label, model in models:\n",
    "    scores = cross_val_score(model, X, y, cv=ShuffleSplit(n_splits=10, test_size=0.15))\n",
    "    print(\"Model %-26s Score: %0.2f (+/- %0.2f)\" % (label, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the random forest and gradient boosting are the best single models. The simple regression models perform significantly worse, so they seem less suited here. Stacking also seems suitable, so that's also a direction worth exploring further for this dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
