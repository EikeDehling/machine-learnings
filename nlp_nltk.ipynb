{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language processing with NLTK\n",
    "\n",
    "This notebooks shows some basic language processing concepts and approaches using the python NLTK library. You can view this as the most basic example approach.\n",
    "\n",
    "Concepts i'm showing explain how to process text. Text processing with machine learning is a bit special, because machine learning algorithms only work on fixed-size vectors of numbers and text is a variable length of words. Also the words in the text are organized in sentences and separated by puntuation and other symbols.\n",
    "\n",
    "In this notebook i'll show how to deal with that by:\n",
    "- Preprocessing (\"cleaning\") the text\n",
    "- Vectorizing the text to fixed-size vectors\n",
    "- Classifying sentiment with a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_unit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>681448150</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681448153</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681448156</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681448158</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681448159</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          airline_sentiment  \\\n",
       "_unit_id                      \n",
       "681448150           neutral   \n",
       "681448153          positive   \n",
       "681448156           neutral   \n",
       "681448158          negative   \n",
       "681448159          negative   \n",
       "\n",
       "                                                                                                                                     text  \n",
       "_unit_id                                                                                                                                   \n",
       "681448150                                                                                             @VirginAmerica What @dhepburn said.  \n",
       "681448153                                                        @VirginAmerica plus you've added commercials to the experience... tacky.  \n",
       "681448156                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!  \n",
       "681448158  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse  \n",
       "681448159                                                                         @VirginAmerica and it's a really big bad thing about it  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/airline_sentiment.csv', index_col=0)\n",
    "\n",
    "pd.set_option('max_colwidth', 140)\n",
    "\n",
    "df[['airline_sentiment', 'text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the first lines of the loaded data. For each tweet we have the sentiment and the text. The sentiment means if this tweet was a positive one, a neutral one or negative.\n",
    "\n",
    "Overall what we'll try to do in this notebook is predict the sentiment value from the text.\n",
    "\n",
    "First step is preprocessing, we'll clean up the text by removing punctuation, lowercasing and splitting into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tweets = df['text'].astype(str).map(lambda txt: [tok.strip('!,.') for tok in txt.lower().split()]).values\n",
    "sentiments = df['airline_sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our text has been cleaned, we can start on creating feature vectors for the machine learning. The way we'll do this, is to represent each tweet by a vector of true/false values indicating which words were present in the tweet.\n",
    "\n",
    "First off, we need to know all the words that exist in this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list()\n",
    "for words in tweets:\n",
    "    all_words.extend(words)\n",
    "    \n",
    "word_dist = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next thing, we define our feature function. This function will transform a single tweet to a list of true/false values for each word indicating if that was present in the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_function(doc):\n",
    "    document_words = set(doc)\n",
    "    #corpus_words = word_dist.keys()\n",
    "    corpus_words = [w for w,f in word_dist.most_common(1000)]\n",
    "    return {\n",
    "        word : (word in document_words)\n",
    "        for word in corpus_words\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next an example of how this looks, for a particular tweet. Note i'm only showing the first 10 entries of the feature vector! Also note most words are not present in the tweet (=False) and a few are present (=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@virginamerica', 'plus', \"you've\", 'added', 'commercials', 'to', 'the', 'experience', 'tacky']\n",
      "[('to', True), ('the', True), ('i', False), ('a', False), ('you', False), ('for', False), ('@united', False), ('flight', False), ('on', False), ('and', False)]\n"
     ]
    }
   ],
   "source": [
    "print(tweets[1])\n",
    "print(list(feature_function(tweets[1]).items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next order of business, we apply the above feature function to all tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = list(nltk.classify.util.apply_features(feature_function, list(zip(tweets, sentiments)), True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes a part that's important to understand in machine learning: Splitting data into the training and the test set.\n",
    "\n",
    "When training a machine learning algorithm, you're learning patterns from the data you're feeding it. When you've trained the algorithm you want to know how good (or bad) it does on new data, data that it hasn't been trained on yet. This is called evaluating. It's important to do that with new, unseen data, else you might learn patterns that only work on the training data.\n",
    "\n",
    "So the correct way to do this is to train on one part of data and then evaluate on another part. It's common to split the available data 80%/20% for example or 75%/25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(processed_data)\n",
    "\n",
    "split_at = int(len(processed_data) * 0.75)\n",
    "train_set, test_set = processed_data[split_at:], processed_data[:split_at]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have preprocessed, vectorized and split up the data, we are ready to train a classifier and see if we can predict the sentiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.classify.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier is trained, so how well does it work?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7585610200364299\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final thing i want to show here, which features or words were most important in predicting the sentiment. Of course you assume works like *thanks* or *good* to indicate positive and unfriendly words to indicate negative. Let's check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   thank = True           positi : negati =     20.8 : 1.0\n",
      "                      ;) = True           positi : negati =     19.6 : 1.0\n",
      "                   hours = True           negati : neutra =     18.4 : 1.0\n",
      "                 awesome = True           positi : negati =     16.8 : 1.0\n",
      "                   great = True           positi : neutra =     16.7 : 1.0\n",
      "               flightled = True           negati : positi =     15.9 : 1.0\n",
      "              appreciate = True           positi : neutra =     15.9 : 1.0\n",
      "                 amazing = True           positi : negati =     15.3 : 1.0\n",
      "     #destinationdragons = True           neutra : negati =     15.2 : 1.0\n",
      "                 despite = True           positi : negati =     11.8 : 1.0\n",
      "               wonderful = True           positi : negati =     11.8 : 1.0\n",
      "                     :-) = True           positi : negati =     11.8 : 1.0\n",
      "                     ceo = True           neutra : negati =     10.9 : 1.0\n",
      "               customers = True           negati : neutra =     10.6 : 1.0\n",
      "                    hold = True           negati : neutra =     10.5 : 1.0\n",
      "                 luggage = True           negati : neutra =     10.4 : 1.0\n",
      "                friendly = True           positi : negati =     10.2 : 1.0\n",
      "                 delayed = True           negati : neutra =     10.0 : 1.0\n",
      "                    ever = True           negati : neutra =      9.9 : 1.0\n",
      "                       4 = True           negati : neutra =      9.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So concluding, we've seen a basic approach of text processing with machine learning and explained some concepts.\n",
    "\n",
    "I hope you enjoyed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
