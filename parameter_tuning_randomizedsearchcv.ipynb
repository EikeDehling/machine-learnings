{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning: RandomizedSearchCV\n",
    "\n",
    "Most machine learning models have so-called hyperparameters that should be tuned for optimum results. There is various utilities for tuning parameters, here i'm going to show how to use the RandomizedSearchCV utility. This utility randomly tries parameter combinations from predefined value ranges to find the best combination. It tries a fixed number of combinations, so the total running time can be limited which can be handy for large datasets and/or models with many parameters. You might not find the absolute best value of course, in a limited number of iterations..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "X,y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we configure the RandomizedSearchCV utility, by specifying the model to be tuned and the parameter ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.493507 using {'max_depth': 4, 'min_samples_leaf': 8, 'min_samples_split': 22, 'n_estimators': 42}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats.distributions import uniform, randint\n",
    "\n",
    "gsc = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_distributions={\n",
    "        'n_estimators': randint(10, 50),\n",
    "        'min_samples_leaf': randint(5, 15),\n",
    "        'min_samples_split': randint(10, 30),\n",
    "        'max_depth': randint(2, 7),\n",
    "    },\n",
    "    cv=ShuffleSplit(n_splits=10, test_size=0.2),\n",
    "    n_jobs=4,\n",
    "    n_iter=100\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X, y)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now with trying just 100 combinations the utility has found a suitable combination of parameters. With an exhaustive search overe the same parameter space we would have tried 40x10x20x5 = 40.000 combinations to find the absolute best result. This is the strength of this utility, quickly exploring the parameter space for a decent solution. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
