{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Workshop : Text Classification\n",
    "\n",
    "In this workshop we'll learn about a NLP (Natural Language Processing) technique called Text Classification. This means to which category a piece of text belongs. An example application of this is sentiment analysis, detecting positive or negative texts.\n",
    "\n",
    "We will use a dataset from crowdflower about hate speech - the use case is detecting offensive language on social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data\n",
    "\n",
    "We start by loading the dataset, for this we use [Pandas](https://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/twitter-hate-speech.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick dataset overview\n",
    "\n",
    "Now that data is loaded we'll habe a quick look at what's available, what information do we have?\n",
    "\n",
    "I'll explain the columns you see in the dataset sample output:\n",
    "\n",
    "- **count** : Number of human annotations for this sample\n",
    "- **hate_speech** : Times annotated as containing hate speech\n",
    "- **offensive_language** : Times annotated as containing offensive language\n",
    "- **neither** : Times annotated as not containing hatefull of offensive language (normal, respectfull language)\n",
    "- **class** : Human annotated category, max votes determines category (0=Hate, 1=Offensive, 2=Neither)\n",
    "- **tweet** : The tweets text\n",
    "\n",
    "From these available columns we'll use **class** as the value we try to predict and **tweet** as input to determine the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                                                                                                                         tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash ou...  \n",
       "1                                                        !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!  \n",
       "2                     !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit  \n",
       "3                                                                               !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny  \n",
       "4    !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 140)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how much data there is in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment : Plot the distribution of class in the dataset\n",
    "\n",
    "An usefull insight can be to have a look at the distriution of categories in the dataset. Plotting can be done using the [Seaborn library](https://seaborn.pydata.org/).\n",
    "\n",
    "**Your assignment is to plot the distrubution (count) of the categories.**\n",
    "\n",
    "After plotting you will notice that the categories are not evenly distributed, category one has many more samples than the others. We'll get back to this later!\n",
    "\n",
    "*Hint: Look at the countplot function in seaborn documentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.countplot(...)  # This line needs to be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text preprocessing\n",
    "\n",
    "In the data above you can see that the text of the tweets contains lot's of slang words, social media specific abbreviations and symbols mixed in. Also there is usernames and hashtags in the text, which we might not want a model to take into consideration for classifying (We'd like the model to learn hatefull/offensive keywords, rather than remember which users use bad language)\n",
    "\n",
    "For this we'll now look at text preprocessing to clean up the data.\n",
    "\n",
    "Two libraries we will use here are [sklean](http://scikit-learn.org) and [gensim](https://radimrehurek.com/gensim/).\n",
    "\n",
    "You can read more here:\n",
    "- [Gensim text preprocessing](https://radimrehurek.com/gensim/parsing/preprocessing.html)\n",
    "- [Sklearn text feature extraction](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "\n",
    "First i will show what the default sklearn and gensim preprocessing functions do, then we'll have a deeper look and customize our own preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whitespace splitting\n",
    "\n",
    "First let's see how the output looks when we simply split on whitespace. What you will see is that the tweets are simpy split up into separate words, all noise such as symbols is retained of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [!!!, RT, @mayasolovely:, As, a, woman, you, shouldn't, complain, about, cleaning, up, your, house., &amp;, as, a, man, you, should, alw...\n",
       "1                                         [!!!!!, RT, @mleew17:, boy, dats, cold...tyga, dwn, bad, for, cuffin, dat, hoe, in, the, 1st, place!!]\n",
       "2    [!!!!!!!, RT, @UrKindOfBrand, Dawg!!!!, RT, @80sbaby4life:, You, ever, fuck, a, bitch, and, she, start, to, cry?, You, be, confused, as,...\n",
       "3                                                                       [!!!!!!!!!, RT, @C_G_Anderson:, @viva_based, she, look, like, a, tranny]\n",
       "4    [!!!!!!!!!!!!!, RT, @ShenikaRoberts:, The, shit, you, hear, about, me, might, be, true, or, it, might, be, faker, than, the, bitch, who,...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].head(n=5).apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn default tokenizer\n",
    "\n",
    "Next up is the sklean tokenizer. This already does some text cleaning, such as removing symbols and stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [rt, mayasolovely, woman, shouldn, complain, cleaning, house, amp, man, trash]\n",
       "1       [rt, mleew17, boy, dats, cold, tyga, dwn, bad, cuffin, dat, hoe, 1st, place]\n",
       "2    [rt, urkindofbrand, dawg, rt, 80sbaby4life, fuck, bitch, start, confused, shit]\n",
       "3                                 [rt, c_g_anderson, viva_based, look, like, tranny]\n",
       "4              [rt, shenikaroberts, shit, hear, true, faker, bitch, told, ya, 57361]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sklearn_default_preprocessor = CountVectorizer(strip_accents='unicode', stop_words='english').build_analyzer()\n",
    "\n",
    "df['tweet'].head(n=5).apply(sklearn_default_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim preprocessor\n",
    "\n",
    "Finally we will have a look at the gensim preprocessor. This does even more cleaning of the text, for example removing short tokens, numbers and it does stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [mayasolov, woman, shouldn, complain, clean, hous, amp, man, trash]\n",
       "1       [mleew, boi, dat, cold, tyga, dwn, bad, cuffin, dat, hoe, place]\n",
       "2      [urkindofbrand, dawg, sbabylif, fuck, bitch, start, confus, shit]\n",
       "3                             [anderson, viva, base, look, like, tranni]\n",
       "4                  [shenikarobert, shit, hear, true, faker, bitch, told]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "df['tweet'].head(n=5).apply(preprocess_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment: Customized preprocessor\n",
    "\n",
    "We have shown a few different approaches for preprocessing text, now we'll create a customized preprocessor that does some extra social media specific data cleaning.\n",
    "\n",
    "For example:\n",
    "- Remove usernames\n",
    "- Remove 'hash' from hashtags\n",
    "- No stemming\n",
    "\n",
    "**Take a look at the code below and complete the preprocessing functions**\n",
    "\n",
    "*Hint: Look at how to lowercase strings and how to use regular expressions in python*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [mayasolovely, woman, shouldn, complain, cleaning, house, amp, man, trash]\n",
       "1                 [mleew, boy, dats, cold, tyga, dwn, bad, cuffin, dat, hoe, place]\n",
       "2    [UrKindOfBrand, Dawg, sbabylife, You, fuck, bitch, start, You, confused, shit]\n",
       "3                                       [Anderson, viva, based, look, like, tranny]\n",
       "4                       [ShenikaRoberts, The, shit, hear, true, faker, bitch, told]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, \\\n",
    "    remove_stopwords\n",
    "\n",
    "def drop_short(tweet):\n",
    "    # This function is included as an example, it removes short tokens\n",
    "    return ' '.join(x for x in tweet.split() if len(x) >= 3)\n",
    "\n",
    "def to_lowercase(tweet):\n",
    "    return tweet  # TODO Complete this function\n",
    "\n",
    "def drop_usernames(tweet):\n",
    "    return tweet  # TODO Complete this function\n",
    "    \n",
    "my_filters = [ to_lowercase, drop_usernames, strip_multiple_whitespaces, strip_punctuation, strip_numeric,\n",
    "               remove_stopwords, drop_short ]\n",
    "\n",
    "df['tweet'].head(n=5).apply(lambda x: preprocess_string(x, my_filters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus assignment: Character NGram preprocessing\n",
    "\n",
    "In this assignment we'll use a different approach towards preprocessing, based on character ngrams. This means instead of splitting into words, the text is split into groups on N letters.\n",
    "\n",
    "**Complete the code below and have a look at the output, experiment with the parameters**\n",
    "\n",
    "For example trigrams (length three) is often used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_preprocessor = CountVectorizer(strip_accents='unicode', analyzer=..., ngram_range=...).build_analyzer()\n",
    "\n",
    "df['tweet'].head(n=5).apply(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature creation\n",
    "\n",
    "In the above section we have preprocessed the text of the tweets and removed noisy or undesireable words. Also the tweets have been split into separate words, this is called tokenization. With this preparation done, we are now ready to transform the data into a format suitable for a machine learning model.\n",
    "\n",
    "Machine learning models generally require numerical input, they don't work on text or words directly. Also machine learning models usually require a fixed amount of input columns or features. So in this section we will transform the variable-length tokenized tweets into a fixed set of features.\n",
    "\n",
    "One method of of transforming variable-length texts to a fixed set of numerical features is using each unique word as a feature, and using the count of that word in the text as the value. This is called bad-of-words, below is an image illustrating this, there is some example sentences and the table shows them transformed into bag-of-words features:\n",
    "\n",
    "1. I love machine learning\n",
    "2. I hate learning boring things\n",
    "3. Machine learning is a passion\n",
    "\n",
    "\n",
    "| Sentence   | I | Love | Machine | Learning | Hate | Boring | Things | Is | A | Passion |\n",
    "| ---------- |:-:|:----:|:-------:|:--------:|:----:|:------:|:------:|:--:|:-:|:-------:|\n",
    "| Sentence 1 | 1 |    1 |       1 |        1 |    0 |      0 |      0 |  0 | 0 |       0 |\n",
    "| Sentence 2 | 1 |    0 |       1 |        0 |    1 |      1 |      1 |  0 | 0 |       0 |\n",
    "| Sentence 3 | 0 |    0 |       1 |        1 |    0 |      0 |      0 |  1 | 1 |       1 | \n",
    "\n",
    "We are going to do the this now for the tweets using a utility from sklearn, a CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "vectorizer = CountVectorizer(strip_accents='unicode', stop_words='english')\n",
    "\n",
    "X = vectorizer.fit_transform(df['tweet'].values)\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at what the output is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24783x35573 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 210603 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 35573)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this transformation has resulted in a matrix of 35573 feature columns, that's probably a few to many. Reason for this is, there is many words appearing once or twice. A machine learning algorithm can't learn much from words that appear so infrequently, or in any case the patterns that it might learn won't apply to many new tweets. So we can safely filter out a lot here. The easiest way is to filter by frequency, we simply drop tokens that appear only in a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=5, strip_accents='unicode', stop_words='english')\n",
    "\n",
    "X_filtered = vectorizer.fit_transform(df['tweet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 4693)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment: Filtering tokens\n",
    "\n",
    "In this exercise we will experiment with filtering tokens by frequency to remove low-frequency tokens, since they would likely not be very usefull anyway.\n",
    "\n",
    "**Experiment with the code below to obtain a feature-matrix of around 500 to 1000 features.**\n",
    "\n",
    "*Hint: Have a look at the min_df parameter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=..., strip_accents='unicode', stop_words='english')\n",
    "\n",
    "X_filtered_more = vectorizer.fit_transform(df['tweet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered_more.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from preprocessed data\n",
    "\n",
    "In the examples above we haven't yet used our preprocessing logic, we had just split up words as default. Let's do this now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, strip_accents='unicode', analyzer='word',\n",
    "                             tokenizer=preprocess_string, stop_words='english')\n",
    "\n",
    "X_preprocessed = vectorizer.fit_transform(df['tweet'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 2164)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment: Plug in our custom preprocessor\n",
    "\n",
    "In this exercise you will plug the custom preprocessor we created earlier in to the vectorizer.\n",
    "\n",
    "**Adjust the code below to use the custom preprocessor logic**\n",
    "\n",
    "*Hint: Use a lambda function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, strip_accents='unicode', analyzer='word',\n",
    "                             tokenizer=..., stop_words='english')\n",
    "\n",
    "X_custom = vectorizer.fit_transform(df['tweet'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus assignment: Character ngrams as features\n",
    "\n",
    "In this assignment we'll use a different approach towards features, based on character ngrams. This means instead of splitting into words, the text is split into groups on N letters.\n",
    "\n",
    "**Make a set of features using character ngrams**\n",
    "\n",
    "*Hint: Look at CountVectorizer documentation, analyzer='char'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing the preprocessing / feature approaches\n",
    "\n",
    "We have now preprocessed the data and created several variants of features from the data. As a next step we'll apply a basic machine learning model and see with approach of preparing data works best.\n",
    "\n",
    "We will use a Naive Bayes model. While this is a relatively simple model, it often works well on textual data especially if there is limited training data.\n",
    "\n",
    "Comparing the data processing approaches is done by cross validation. In the basis, this mean splitting up the data into a training and test set, where the model is trained on the training data and then evaluated on the test data. In this case i'm using an improved cross validation approach where data is shuffled and split up into N different training/test combinations, we then average the scores.\n",
    "\n",
    "Here is an image to visualize this cross validation:\n",
    "\n",
    "![Cross Validation](./img/cross-validation.png \"Cross Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.87 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2)\n",
    "\n",
    "scores = cross_val_score(MultinomialNB(), X, y, cv=cv)\n",
    "print(\"Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment: Comparing features\n",
    "\n",
    "Above is shown how to compute the score of one approach of preprocessing. Now it's time to compute the scores for the other approaches.\n",
    "\n",
    "**Compute the scores for the other preprocessing and feature approaches, analoguous to above**\n",
    "\n",
    "*Hint: Copy and adjust the code above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Machine learning models\n",
    "\n",
    "Above we have compared various preprocessing and feature approaches to see how they do, we used a naive bayes model there. Of course there is many machine learning models that can be used. In this section we'll have a look at a few machine learning models that are popular in the NLP area.\n",
    "\n",
    "We'll compute scores for various models, all using the filtered dataset.\n",
    "\n",
    "First is the baseline, naive bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.87 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(MultinomialNB(), X, y, cv=cv)\n",
    "print(\"Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment: Compute scores with other models\n",
    "\n",
    "In this assignment you will compute scores for several other machine learning models.\n",
    "\n",
    "**Complete the code below and compute scores for all models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "models = [\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(),\n",
    "    LogisticRegression(multi_class='multinomial', solver='newton-cg'),\n",
    "    DecisionTreeClassifier(min_samples_split=50),\n",
    "    GradientBoostingClassifier(),\n",
    "    LinearSVC()\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation metrics & class imbalance\n",
    "\n",
    "We have now evaluated several approaches of preprocessing, feature creation and different machine learning models. For this evaluation we have used cross validation using a default metric, accuracy.\n",
    "\n",
    "It's good to keep in mind, such an evaluation metric just one number, that means it is a very simplified view of the world. In many cases it can be good practise to use different evaluation metrics and do more in-depth diagnosis of your machine learning model to determine how well it is really doing.\n",
    "\n",
    "Let's calculate a few different metrics and see what this tells us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric accuracy score: 0.89 (+/- 0.01)\n",
      "Metric f1_micro score: 0.88 (+/- 0.00)\n",
      "Metric f1_macro score: 0.69 (+/- 0.01)\n",
      "Metric f1_weighted score: 0.88 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "metrics = [\n",
    "    'accuracy',\n",
    "    'f1_micro',\n",
    "    'f1_macro',\n",
    "    'f1_weighted'\n",
    "]\n",
    "\n",
    "for metric in metrics:\n",
    "    scores = cross_val_score(MultinomialNB(), X_filtered, y, cv=cv, scoring=metric)\n",
    "    print(\"Metric %s score: %0.2f (+/- %0.2f)\" % (metric, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics used above are accuracy and F1 score, with several variants of the F1 metric. The variants of the F1 metric are weighted differently for multiclass and could tell us something about if we have similar performance on each class/category. Apparently we do not! \n",
    "\n",
    "Let's have a closer look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Hate       0.50      0.25      0.34       304\n",
      "  Offensive       0.93      0.96      0.94      3813\n",
      "    Neither       0.84      0.87      0.86       840\n",
      "\n",
      "avg / total       0.89      0.90      0.89      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_filtered, y, test_size=0.2)\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=('Hate', 'Offensive', 'Neither')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report above tells something about how well we do for the different classes / categories. In this case it seems we doing great in some and less well in other cases.\n",
    "\n",
    "One reason for this could be the imbalance in the dataset, the support column above tells you how many data samples there were per category. Remember the distribution plot we made earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f272687cd30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.countplot(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weighting\n",
    "\n",
    "The effect this imbalance has, is that because there are many more samples for the 'Offensive' class, those have a larger impact on the training of the model.\n",
    "\n",
    "One way of dealing with this is weighting errors for each classes differently to compensate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Hate       0.30      0.56      0.39       296\n",
      "  Offensive       0.96      0.86      0.91      3781\n",
      "    Neither       0.82      0.93      0.87       880\n",
      "\n",
      "avg / total       0.89      0.85      0.87      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='newton-cg', class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=('Hate', 'Offensive', 'Neither')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above has slightly improved the situation, but results are still not ideal. We can try out different versions of weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Hate       0.36      0.46      0.41       296\n",
      "  Offensive       0.95      0.90      0.93      3781\n",
      "    Neither       0.82      0.92      0.87       880\n",
      "\n",
      "avg / total       0.89      0.88      0.88      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='newton-cg', class_weight={0: 5.0, 1: 1.0, 2: 5.0})\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=('Hate', 'Offensive', 'Neither')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignemnt: Class weighting\n",
    "\n",
    "In this assignment we will experiment with class weighting to improve model performance on classes with fewer samples.\n",
    "\n",
    "**Experiment with class weights and try to find parameters that improve the F1 score for the categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-sampling\n",
    "\n",
    "Another approach to dealing with class imbalance is re-sampling. One library for this is SMOTE. Let's have a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Hate       0.29      0.55      0.38       304\n",
      "  Offensive       0.95      0.87      0.91      3813\n",
      "    Neither       0.83      0.88      0.85       840\n",
      "\n",
      "avg / total       0.89      0.85      0.87      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test), target_names=('Hate', 'Offensive', 'Neither')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asignment: Re-sampling methods\n",
    "\n",
    "We showed how to use one particular resampling method, there are many more of course. Here you can experiment with a few.\n",
    "\n",
    "**Try out a few re-sampling methods and see if they improve the scores.**\n",
    "\n",
    "*Hint have a look at imbalanced-learn documentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
