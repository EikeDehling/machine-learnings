{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Workshop : Text Classification\n",
    "\n",
    "In this workshop we'll learn about a NLP (Natural Language Processing) technique called Text Classification. This means to which category a piece of text belongs. An example application of this is sentiment analysis, detecting positive or negative texts.\n",
    "\n",
    "We will use a dataset from crowdflower about hate speech - the use case is detecting offensive language on social media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data\n",
    "\n",
    "We start by loading the dataset, for this we use [Pandas](https://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/twitter-hate-speech.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quick dataset overview\n",
    "\n",
    "Now that data is loaded we'll habe a quick look at what's available, what information do we have?\n",
    "\n",
    "I'll explain the columns you see in the dataset sample output:\n",
    "\n",
    "- **count** : Number of human annotations for this sample\n",
    "- **hate_speech** : Times annotated as containing hate speech\n",
    "- **offensive_language** : Times annotated as containing offensive language\n",
    "- **neither** : Times annotated as not containing hatefull of offensive language (normal, respectfull language)\n",
    "- **class** : Human annotated category, max votes determines category (0=Hate, 1=Offensive, 2=Neither)\n",
    "- **tweet** : The tweets text\n",
    "\n",
    "From these available columns we'll use **class** as the value we try to predict and **tweet** as input to determine the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                                                                                                                         tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash ou...  \n",
       "1                                                        !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!  \n",
       "2                     !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit  \n",
       "3                                                                               !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny  \n",
       "4    !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 140)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment : Plot the distribution of class in the dataset\n",
    "\n",
    "An usefull insight can be to have a look at the distriution of categories in the dataset. Plotting can be done using the [Seaborn library](https://seaborn.pydata.org/).\n",
    "\n",
    "**Your assignment is to plot the distrubution (count) of the categories.**\n",
    "\n",
    "After plotting you will notice that the categories are not evenly distributed, category one has many more samples than the others. We'll get back to this later!\n",
    "\n",
    "*Hint: Look at the countplot function in seaborn documentation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.countplot(...)  # This line needs to be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text preprocessing\n",
    "\n",
    "In the data above you can see that the text of the tweets contains lot's of slang words, social media specific abbreviations and symbols mixed in. Also there is usernames and hashtags in the text, which we might not want a model to take into consideration for classifying (We'd like the model to learn hatefull/offensive keywords, rather than remember which users use bad language)\n",
    "\n",
    "For this we'll now look at text preprocessing to clean up the data.\n",
    "\n",
    "Two libraries we will use here are [sklean](http://scikit-learn.org) and [gensim](https://radimrehurek.com/gensim/).\n",
    "\n",
    "You can read more here:\n",
    "- [Gensim text preprocessing](https://radimrehurek.com/gensim/parsing/preprocessing.html)\n",
    "- [Sklearn text feature extraction](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
    "\n",
    "First i will show what the default sklearn and gensim preprocessing functions do, then we'll have a deeper look and customize our own preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whitespace splitting\n",
    "\n",
    "First let's see how the output looks when we simply split on whitespace. What you will see is that the tweets are simpy split up into separate words, all noise such as symbols is retained of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [!!!, RT, @mayasolovely:, As, a, woman, you, shouldn't, complain, about, cleaning, up, your, house., &amp;, as, a, man, you, should, alw...\n",
       "1                                         [!!!!!, RT, @mleew17:, boy, dats, cold...tyga, dwn, bad, for, cuffin, dat, hoe, in, the, 1st, place!!]\n",
       "2    [!!!!!!!, RT, @UrKindOfBrand, Dawg!!!!, RT, @80sbaby4life:, You, ever, fuck, a, bitch, and, she, start, to, cry?, You, be, confused, as,...\n",
       "3                                                                       [!!!!!!!!!, RT, @C_G_Anderson:, @viva_based, she, look, like, a, tranny]\n",
       "4    [!!!!!!!!!!!!!, RT, @ShenikaRoberts:, The, shit, you, hear, about, me, might, be, true, or, it, might, be, faker, than, the, bitch, who,...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'].head(n=5).apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn default tokenizer\n",
    "\n",
    "Next up is the sklean tokenizer. This already does some text cleaning, such as removing symbols and stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [rt, mayasolovely, woman, shouldn, complain, cleaning, house, amp, man, trash]\n",
       "1       [rt, mleew17, boy, dats, cold, tyga, dwn, bad, cuffin, dat, hoe, 1st, place]\n",
       "2    [rt, urkindofbrand, dawg, rt, 80sbaby4life, fuck, bitch, start, confused, shit]\n",
       "3                                 [rt, c_g_anderson, viva_based, look, like, tranny]\n",
       "4              [rt, shenikaroberts, shit, hear, true, faker, bitch, told, ya, 57361]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "sklearn_default_preprocessor = CountVectorizer(strip_accents='unicode', stop_words='english').build_analyzer()\n",
    "\n",
    "df['tweet'].head(n=5).apply(sklearn_default_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim preprocessor\n",
    "\n",
    "Finally we will have a look at the gensim preprocessor. This does even more cleaning of the text, for example removing short tokens, numbers and it does stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [mayasolov, woman, shouldn, complain, clean, hous, amp, man, trash]\n",
       "1       [mleew, boi, dat, cold, tyga, dwn, bad, cuffin, dat, hoe, place]\n",
       "2      [urkindofbrand, dawg, sbabylif, fuck, bitch, start, confus, shit]\n",
       "3                             [anderson, viva, base, look, like, tranni]\n",
       "4                  [shenikarobert, shit, hear, true, faker, bitch, told]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "df['tweet'].head(n=5).apply(preprocess_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment: Customized preprocessor\n",
    "\n",
    "We have shown a few different approaches for preprocessing text, now we'll create a customized preprocessor that does some extra social media specific data cleaning.\n",
    "\n",
    "For example:\n",
    "- Remove usernames\n",
    "- Remove 'hash' from hashtags\n",
    "- No stemming\n",
    "\n",
    "**Take a look at the code below and complete the preprocessing functions**\n",
    "\n",
    "*Hint: Look at how to lowercase strings and how to use regular expressions in python*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [mayasolovely, woman, shouldn, complain, cleaning, house, amp, man, trash]\n",
       "1                 [mleew, boy, dats, cold, tyga, dwn, bad, cuffin, dat, hoe, place]\n",
       "2    [UrKindOfBrand, Dawg, sbabylife, You, fuck, bitch, start, You, confused, shit]\n",
       "3                                       [Anderson, viva, based, look, like, tranny]\n",
       "4                       [ShenikaRoberts, The, shit, hear, true, faker, bitch, told]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, \\\n",
    "    remove_stopwords\n",
    "\n",
    "def drop_short(tweet):\n",
    "    # This function is included as an example, it removes short tokens\n",
    "    return ' '.join(x for x in tweet.split() if len(x) >= 3)\n",
    "\n",
    "def to_lowercase(tweet):\n",
    "    return tweet  # TODO Complete this function\n",
    "\n",
    "def drop_usernames(tweet):\n",
    "    return tweet  # TODO Complete this function\n",
    "    \n",
    "my_filters = [ to_lowercase, drop_usernames, strip_multiple_whitespaces, strip_punctuation, strip_numeric,\n",
    "               remove_stopwords, drop_short ]\n",
    "\n",
    "df['tweet'].head(n=5).apply(lambda x: preprocess_string(x, my_filters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature creation\n",
    "\n",
    "\n",
    "Bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "simple = CountVectorizer(min_df=25, max_df=0.75, strip_accents='unicode', analyzer='word')\n",
    "\n",
    "count = CountVectorizer(min_df=25, max_df=0.75, strip_accents='unicode', analyzer='word',\n",
    "                        tokenizer=preprocess_string, stop_words='english')\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=25, max_df=0.75, strip_accents='unicode', analyzer='word',\n",
    "                        tokenizer=preprocess_string, stop_words='english')\n",
    "\n",
    "trigrams = CountVectorizer(min_df=25, max_df=0.75, strip_accents='ascii', analyzer='char',\n",
    "                           ngram_range=(3, 3))\n",
    "\n",
    "X_simple = simple.fit_transform(df['tweet'].values)\n",
    "X_count = count.fit_transform(df['tweet'].values)\n",
    "X_tfidf = tfidf.fit_transform(df['tweet'].values)\n",
    "X_trigrams = trigrams.fit_transform(df['tweet'].values)\n",
    "\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing the preprocessing / feature approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Simple score: 0.88 (+/- 0.00)\n",
      "Features Count score: 0.89 (+/- 0.00)\n",
      "Features TF/IDF score: 0.85 (+/- 0.00)\n",
      "Features Trigrams score: 0.82 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "scores = cross_val_score(MultinomialNB(), X_simple, y, cv=ShuffleSplit(n_splits=10, test_size=0.2))\n",
    "print(\"Features %s score: %0.2f (+/- %0.2f)\" % ('Simple', scores.mean(), scores.std()))\n",
    "\n",
    "scores = cross_val_score(MultinomialNB(), X_count, y, cv=ShuffleSplit(n_splits=10, test_size=0.2))\n",
    "print(\"Features %s score: %0.2f (+/- %0.2f)\" % ('Count', scores.mean(), scores.std()))\n",
    "\n",
    "scores = cross_val_score(MultinomialNB(), X_tfidf, y, cv=ShuffleSplit(n_splits=10, test_size=0.2))\n",
    "print(\"Features %s score: %0.2f (+/- %0.2f)\" % ('TF/IDF', scores.mean(), scores.std()))\n",
    "\n",
    "scores = cross_val_score(MultinomialNB(), X_trigrams, y, cv=ShuffleSplit(n_splits=10, test_size=0.2))\n",
    "print(\"Features %s score: %0.2f (+/- %0.2f)\" % ('Trigrams', scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LogisticRegression score: 0.90 (+/- 0.00)\n",
      "Model MultinomialNB score: 0.89 (+/- 0.00)\n",
      "Model DecisionTreeClassifier score: 0.88 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(multi_class='multinomial', solver='newton-cg'),\n",
    "    MultinomialNB(),\n",
    "    DecisionTreeClassifier(min_samples_split=50)\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    scores = cross_val_score(model, X_count, y, cv=ShuffleSplit(n_splits=10, test_size=0.2))\n",
    "    print(\"Model %s score: %0.2f (+/- %0.2f)\" % (model.__class__.__name__, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LogisticRegression score: 0.83 (+/- 0.00)\n",
      "Model DecisionTreeClassifier score: 0.83 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    LogisticRegression(multi_class='multinomial', solver='newton-cg', class_weight='balanced'),\n",
    "    DecisionTreeClassifier(min_samples_split=50, class_weight='balanced')\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    scores = cross_val_score(model, X_count, y, cv=ShuffleSplit(n_splits=10, test_size=0.2))\n",
    "    print(\"Model %s score: %0.2f (+/- %0.2f)\" % (model.__class__.__name__, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detailed evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Hate       0.46      0.23      0.31       294\n",
      "  Offensive       0.91      0.96      0.93      3850\n",
      "    Neither       0.84      0.78      0.81       813\n",
      "\n",
      "avg / total       0.87      0.89      0.88      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_count, y, test_size=0.2)\n",
    "\n",
    "lr = MultinomialNB()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, lr.predict(X_test), target_names=('Hate', 'Offensive', 'Neither')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
